crunchy-postgres:
  fullnameOverride: ha-postgres-crunchydb
  crunchyImage: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
  # crunchyImage: artifacts.developer.gov.bc.ca/bcgov-docker-local/crunchy-postgres-gis:ubi8-15.2-3.3-0 # use this image for POSTGIS
  postgresVersion: 16
  # postGISVersion: '3.3' # use this version of POSTGIS. both crunchyImage and this property needs to have valid values for POSTGIS to be enabled.
  imagePullPolicy: IfNotPresent

# enable to bootstrap a standby cluster from backup. Then disable to promote this standby to primary
  standby:
    enabled: false
    # If you want to recover from PVC, use repo1. If you want to recover from S3, use repo2
    repoName: repo1

  instances:
    name: ha # high availability
    replicas: 1
    dataVolumeClaimSpec:
      storage: 1Gi
      storageClassName: netapp-block-standard
    requests:
      cpu: 10m
      memory: 256Mi
    limits: # wanted to just leave limits blank here, but the underlying chart speciffies it, so instead just specify a large number
      cpu: 1
      memory: 4Gi
    replicaCertCopy:
      requests:
        cpu: 10m
        memory: 32Mi
      limits:
        cpu: 50m
        memory: 64Mi

  pgBackRest:
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    retention: "1" # Ideally a larger number such as 30 backups/days
    # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
    # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
    retentionFullType: count
    repos:
      schedules:
        full: 0 4 * * *
        incremental: 0 0,6,12,16,20 * * *
      volume:
        accessModes: "ReadWriteOnce"
        storage: 1Gi
        storageClassName: netapp-file-backup
    repoHost:
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 200m
        memory: 512Mi
    sidecars:
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 200m
        memory: 256Mi
    s3:
      enabled: false
      createS3Secret: true
      # the s3 secret name
      s3Secret: s3-pgbackrest
      # the path start with /, it will be created under bucket if it doesn't exist
      s3Path: "/habackup"
      # s3UriStyle is host or path
      s3UriStyle: path
      # bucket specifies the S3 bucket to use,
      bucket: "backetName"
      # endpoint specifies the S3 endpoint to use.
      endpoint: "endpointName"
      # region specifies the S3 region to use. If your S3 storage system does not
      # use "region", fill this in with a random value.
      region: "ca-central-1"
      # key is the S3 key. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      key: "s3keyValue"
      # keySecret is the S3 key secret. This is stored in a Secret.
      # Please DO NOT push this value to GitHub
      keySecret: "s3SecretValue"

  patroni:
    postgresql:
      pg_hba: 
        - "host all all 0.0.0.0/0 md5"
        - "local all postgres trust" # trust local system socket connections user postgres
        - "host all all 127.0.0.1/32 trust" # trust IPv4 local connections includes port forwarding
        - "host all all ::1/128 trust" # trust IPv6 local connections includes port forwarding
        - "host all all 10.0.0.0/8 md5" # Allow any users to connect to any database from 10.x.x.x private subnet range if password is correctly supplied
      parameters:
        shared_buffers: 16MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
        wal_buffers: "64kB" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
        min_wal_size: 32MB
        max_wal_size: 64MB # default is 1GB
        max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind
        temp_file_limit: 200MB  # Prevent temp files from filling PVC
        checkpoint_timeout: 15min  # Reduce checkpoint frequency
        checkpoint_completion_target: 0.9  # Smooth checkpointing

  proxy:
    pgBouncer:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      replicas: 2
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 500m
        memory: 256Mi

  # Postgres Cluster resource values:
  pgmonitor:
    enabled: false
    exporter:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 200m
        memory: 256Mi
